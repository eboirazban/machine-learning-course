{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957f0e3a-6b23-4006-b63b-9639c422eea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to C:\\Users\\eboir\\.cache\\kagglehub\\datasets\\thedevastator\\uncovering-factors-that-affect-used-car-prices\\1.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18.2M/18.2M [00:02<00:00, 6.53MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\eboir\\.cache\\kagglehub\\datasets\\thedevastator\\uncovering-factors-that-affect-used-car-prices\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"thedevastator/uncovering-factors-that-affect-used-car-prices\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8701718-31a5-441b-a348-f6a1417d668b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'autos.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mautos.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlatin1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# –ß–∞—Å—Ç–æ –Ω—É–∂–Ω–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∞ –¥–ª—è —ç—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 2. –ü–µ—Ä–≤–∏—á–Ω—ã–π –æ–±–∑–æ—Ä\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:\u001b[39m\u001b[33m\"\u001b[39m, df.shape) \u001b[38;5;66;03m# ~370k —Å—Ç—Ä–æ–∫, 21 —Å—Ç–æ–ª–±–µ—Ü\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'autos.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "df = pd.read_csv('autos.csv', encoding='latin1') # –ß–∞—Å—Ç–æ –Ω—É–∂–Ω–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∞ –¥–ª—è —ç—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "\n",
    "# 2. –ü–µ—Ä–≤–∏—á–Ω—ã–π –æ–±–∑–æ—Ä\n",
    "print(\"–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:\", df.shape) # ~370k —Å—Ç—Ä–æ–∫, 21 —Å—Ç–æ–ª–±–µ—Ü\n",
    "print(\"\\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\")\n",
    "print(df.head())\n",
    "print(\"\\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–∏–ø–∞—Ö:\")\n",
    "print(df.info())\n",
    "print(\"\\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f08c5530-a071-4f24-8ffc-f8d54636a927",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1080600137.py, line 345)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 345\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m/\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# –ò–ú–ü–û–†–¢ –ë–ò–ë–õ–ò–û–¢–ï–ö\n",
    "# =============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥—Ä–∞—Ñ–∏–∫–æ–≤\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"–ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–• –û –ü–û–î–ï–†–ñ–ê–ù–ù–´–• –ê–í–¢–û–ú–û–ë–ò–õ–Ø–•\")\n",
    "print(\"–î–∞—Ç–∞—Å–µ—Ç: Uncovering Factors That Affect Used Car Prices\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# =============================\n",
    "# 1. –ü–û–õ–£–ß–ï–ù–ò–ï –ü–£–¢–ò –ò –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•\n",
    "# =============================\n",
    "print(\"\\n1. –ü–û–õ–£–ß–ï–ù–ò–ï –ü–£–¢–ò –ò –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å, –∫–æ—Ç–æ—Ä—ã–π –≤–µ—Ä–Ω—É–ª kagglehub\n",
    "# path = kagglehub.dataset_download(\"thedevastator/uncovering-factors-that-affect-used-car-prices\")\n",
    "# print(f\"–ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º: {path}\")\n",
    "\n",
    "# –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –¥–∞–≤–∞–π—Ç–µ —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä–∏–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é\n",
    "current_dir = os.getcwd()\n",
    "print(f\"–¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {current_dir}\")\n",
    "\n",
    "# –ü–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫–∏–µ CSV —Ñ–∞–π–ª—ã –µ—Å—Ç—å –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
    "csv_files = [f for f in os.listdir() if f.endswith('.csv')]\n",
    "print(f\"CSV —Ñ–∞–π–ª—ã –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {csv_files}\")\n",
    "\n",
    "if 'autos.csv' in csv_files:\n",
    "    print(\"‚úì –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª autos.csv –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\")\n",
    "    file_path = 'autos.csv'\n",
    "elif csv_files:\n",
    "    file_path = csv_files[0]\n",
    "    print(f\"‚úì –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π CSV —Ñ–∞–π–ª: {file_path}\")\n",
    "else:\n",
    "    print(\"CSV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–æ–∑–¥–∞—é –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...\")\n",
    "    file_path = None\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–∞–π–¥–µ–Ω\n",
    "if file_path:\n",
    "    try:\n",
    "        # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏\n",
    "        encodings = ['latin1', 'ISO-8859-1', 'cp1252', 'utf-8']\n",
    "        \n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding=encoding, nrows=100000)  # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–≤—ã–µ 100–∫ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏\n",
    "                print(f\"‚úì –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π {encoding}\")\n",
    "                print(f\"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π (–ø–µ—Ä–≤—ã–µ 100,000)\")\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        else:\n",
    "            # –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∞ –Ω–µ –ø–æ–¥–æ—à–ª–∞\n",
    "            df = pd.read_csv(file_path, encoding='latin1', nrows=100000, errors='ignore')\n",
    "            print(\"‚úì –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω —Å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫ –∫–æ–¥–∏—Ä–æ–≤–∫–∏\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}\")\n",
    "        file_path = None\n",
    "\n",
    "# –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è, —Å–æ–∑–¥–∞–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ\n",
    "if 'df' not in locals():\n",
    "    print(\"\\n–°–æ–∑–¥–∞—é –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...\")\n",
    "    \n",
    "    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π (–¥–æ–ª–∂–Ω–æ —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ 1)\n",
    "    np.random.seed(42)\n",
    "    n_samples = 5000  # –£–≤–µ–ª–∏—á–∏–º –¥–ª—è –±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\n",
    "    \n",
    "    brands = ['Volkswagen', 'BMW', 'Opel', 'Mercedes-Benz', 'Audi', 'Ford', \n",
    "              'Renault', 'Peugeot', 'Fiat', 'Seat', 'Skoda', 'Toyota']\n",
    "    \n",
    "    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª–µ—Ç (–≤ —Å—É–º–º–µ 1.0)\n",
    "    # 1990-1994: 5 –ª–µ—Ç √ó 0.01 = 0.05\n",
    "    # 1995-2004: 10 –ª–µ—Ç √ó 0.02 = 0.20\n",
    "    # 2005-2009: 5 –ª–µ—Ç √ó 0.03 = 0.15\n",
    "    # 2010-2014: 5 –ª–µ—Ç √ó 0.04 = 0.20\n",
    "    # 2015-2022: 8 –ª–µ—Ç √ó 0.05 = 0.40\n",
    "    # –ò—Ç–æ–≥–æ: 0.05 + 0.20 + 0.15 + 0.20 + 0.40 = 1.00\n",
    "    \n",
    "    years_range = np.arange(1990, 2023)  # 33 –≥–æ–¥–∞\n",
    "    # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π\n",
    "    p = []\n",
    "    for year in years_range:\n",
    "        if year < 1995:\n",
    "            p.append(0.01)  # 0.05 –≤ —Å—É–º–º–µ\n",
    "        elif year < 2005:\n",
    "            p.append(0.02)  # 0.20 –≤ —Å—É–º–º–µ\n",
    "        elif year < 2010:\n",
    "            p.append(0.03)  # 0.15 –≤ —Å—É–º–º–µ\n",
    "        elif year < 2015:\n",
    "            p.append(0.04)  # 0.20 –≤ —Å—É–º–º–µ\n",
    "        else:\n",
    "            p.append(0.05)  # 0.40 –≤ —Å—É–º–º–µ\n",
    "    \n",
    "    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —á—Ç–æ–±—ã —Å—É–º–º–∞ –±—ã–ª–∞ —Ç–æ—á–Ω–æ 1\n",
    "    p = np.array(p) / np.sum(p)\n",
    "    \n",
    "    years = np.random.choice(years_range, n_samples, p=p)\n",
    "    \n",
    "    # –ü—Ä–æ–±–µ–≥ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≥–æ–¥–∞ (—Å—Ç–∞—Ä—ã–µ –º–∞—à–∏–Ω—ã –∏–º–µ—é—Ç –±–æ–ª—å—à–∏–π –ø—Ä–æ–±–µ–≥)\n",
    "    base_mileage = 10000 * (2023 - years)  # ~10,000 –∫–º –≤ –≥–æ–¥\n",
    "    mileage = np.random.normal(base_mileage, 30000, n_samples)\n",
    "    mileage = np.maximum(mileage, 1000)  # –ú–∏–Ω–∏–º—É–º 1000 –∫–º\n",
    "    mileage = np.minimum(mileage, 400000)  # –ú–∞–∫—Å–∏–º—É–º 400,000 –∫–º\n",
    "    \n",
    "    # –¶–µ–Ω–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≥–æ–¥–∞, –±—Ä–µ–Ω–¥–∞ –∏ –ø—Ä–æ–±–µ–≥–∞\n",
    "    brand_multiplier = {\n",
    "        'Volkswagen': 1.0, 'BMW': 1.8, 'Opel': 0.8, 'Mercedes-Benz': 2.0,\n",
    "        'Audi': 1.7, 'Ford': 0.9, 'Renault': 0.85, 'Peugeot': 0.8,\n",
    "        'Fiat': 0.7, 'Seat': 0.9, 'Skoda': 0.95, 'Toyota': 1.1\n",
    "    }\n",
    "    \n",
    "    base_price = 8000 + (years - 2000) * 600  # –ë–∞–∑–æ–≤–∞—è —Ü–µ–Ω–∞ –ø–æ –≥–æ–¥—É\n",
    "    prices = []\n",
    "    selected_brands = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        brand = np.random.choice(brands)\n",
    "        selected_brands.append(brand)\n",
    "        # –¶–µ–Ω–∞ = –±–∞–∑–æ–≤–∞—è √ó –º–Ω–æ–∂–∏—Ç–µ–ª—å –±—Ä–µ–Ω–¥–∞ - –∏–∑–Ω–æ—Å –æ—Ç –ø—Ä–æ–±–µ–≥–∞ + —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å\n",
    "        price = base_price[i] * brand_multiplier[brand]\n",
    "        price = price * (1 - mileage[i] / 400000 * 0.7)  # –ò–∑–Ω–æ—Å –¥–æ 70% –æ—Ç –ø—Ä–æ–±–µ–≥–∞\n",
    "        price += np.random.normal(0, 1500)  # –°–ª—É—á–∞–π–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞\n",
    "        prices.append(max(800, price))  # –ú–∏–Ω–∏–º—É–º 800 –µ–≤—Ä–æ\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º DataFrame —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "    df = pd.DataFrame({\n",
    "        'name': [f'{brand} {model}' for brand, model in zip(selected_brands, \n",
    "                np.random.choice(['Golf', '3er', 'Corsa', 'C-Class', 'A4', 'Focus', \n",
    "                                  'Clio', '308', 'Punto', 'Leon', 'Octavia', 'Corolla'], n_samples))],\n",
    "        'seller': np.random.choice(['private', 'dealer'], n_samples, p=[0.7, 0.3]),\n",
    "        'price': np.round(prices).astype(int),\n",
    "        'vehicleType': np.random.choice(['sedan', 'SUV', 'coupe', 'wagon', 'van', 'convertible'], \n",
    "                                        n_samples, p=[0.4, 0.25, 0.1, 0.15, 0.05, 0.05]),\n",
    "        'yearOfRegistration': years,\n",
    "        'gearbox': np.random.choice(['manual', 'automatic'], n_samples, p=[0.6, 0.4]),\n",
    "        'powerPS': np.random.randint(60, 350, n_samples),\n",
    "        'model': np.random.choice(['Golf', '3 Series', 'Corsa', 'C-Class', 'A4', 'Focus', \n",
    "                                   'Clio', '308', 'Punto', 'Leon', 'Octavia', 'Corolla'], n_samples),\n",
    "        'kilometer': mileage.astype(int),\n",
    "        'fuelType': np.random.choice(['petrol', 'diesel', 'electric', 'hybrid'], \n",
    "                                     n_samples, p=[0.6, 0.3, 0.05, 0.05]),\n",
    "        'brand': selected_brands,\n",
    "        'notRepairedDamage': np.random.choice(['yes', 'no'], n_samples, p=[0.15, 0.85]),\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úì –°–æ–∑–¥–∞–Ω –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {len(df)} –∑–∞–ø–∏—Å–µ–π\")\n",
    "\n",
    "# =============================\n",
    "# 2. –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–•\n",
    "# =============================\n",
    "print(\"\\n2. –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–•\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(f\"–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {df.shape[0]:,} —Å—Ç—Ä–æ–∫ √ó {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n",
    "print(f\"\\n–ù–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ ({len(df.columns)}):\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2}. {col}\")\n",
    "\n",
    "print(\"\\n–ü–µ—Ä–≤—ã–µ 3 –∑–∞–ø–∏—Å–∏:\")\n",
    "print(df.head(3).to_string())\n",
    "\n",
    "print(\"\\n–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(df.dtypes.to_string())\n",
    "\n",
    "# =============================\n",
    "# 3. –ë–´–°–¢–†–´–ô –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –î–ê–ù–ù–´–•\n",
    "# =============================\n",
    "print(\"\\n3. –ë–´–°–¢–†–´–ô –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –î–ê–ù–ù–´–•\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "missing_total = df.isnull().sum().sum()\n",
    "missing_percent = (missing_total / (df.shape[0] * df.shape[1])) * 100\n",
    "print(f\"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤: {missing_total:,}\")\n",
    "print(f\"–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö: {missing_percent:.2f}%\")\n",
    "\n",
    "# –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–µ\n",
    "print(\"\\n–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º:\")\n",
    "for col in df.columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    if unique_count < 20:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫ —Å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "        print(f\"{col:20} - {unique_count:3} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {list(df[col].dropna().unique())[:10]}\")\n",
    "\n",
    "# =============================\n",
    "# 4. –ë–ê–ó–û–í–ê–Ø –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø - –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –¶–ï–ù–´\n",
    "# =============================\n",
    "print(\"\\n4. –ë–ê–ó–û–í–ê–Ø –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Ü–µ–Ω\n",
    "axes[0].hist(df['price'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π')\n",
    "axes[0].set_xlabel('–¶–µ–Ω–∞ (‚Ç¨)')\n",
    "axes[0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫\n",
    "mean_price = df['price'].mean()\n",
    "median_price = df['price'].median()\n",
    "axes[0].axvline(mean_price, color='red', linestyle='--', label=f'–°—Ä–µ–¥–Ω—è—è: {mean_price:,.0f}‚Ç¨')\n",
    "axes[0].axvline(median_price, color='green', linestyle='--', label=f'–ú–µ–¥–∏–∞–Ω–∞: {median_price:,.0f}‚Ç¨')\n",
    "axes[0].legend()\n",
    "\n",
    "# 2. –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ü–µ–Ω—ã –æ—Ç –≥–æ–¥–∞\n",
    "if 'yearOfRegistration' in df.columns:\n",
    "    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –≥–æ–¥—É –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏\n",
    "    year_price = df.groupby('yearOfRegistration')['price'].mean().reset_index()\n",
    "    axes[1].scatter(year_price['yearOfRegistration'], year_price['price'], alpha=0.6)\n",
    "    axes[1].set_title('–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –ø–æ –≥–æ–¥—É –≤—ã–ø—É—Å–∫–∞')\n",
    "    axes[1].set_xlabel('–ì–æ–¥ –≤—ã–ø—É—Å–∫–∞')\n",
    "    axes[1].set_ylabel('–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ (‚Ç¨)')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ü–µ–Ω—ã –æ—Ç –ø—Ä–æ–±–µ–≥–∞\n",
    "if 'kilometer' in df.columns:\n",
    "    # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é –ø–æ–¥–≤—ã–±–æ—Ä–∫—É –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏\n",
    "    sample_size = min(1000, len(df))\n",
    "    sample_indices = np.random.choice(df.index, sample_size, replace=False)\n",
    "    df_sample = df.loc[sample_indices]\n",
    "    \n",
    "    axes[2].scatter(df_sample['kilometer'], df_sample['price'], alpha=0.5, s=10)\n",
    "    axes[2].set_title('–¶–µ–Ω–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–±–µ–≥–∞')\n",
    "    axes[2].set_xlabel('–ü—Ä–æ–±–µ–≥ (–∫–º)')\n",
    "    axes[2].set_ylabel('–¶–µ–Ω–∞ (‚Ç¨)')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================\n",
    "# 5. –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –¶–ï–ù–´\n",
    "# =============================\n",
    "print(\"\\n5. –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –¶–ï–ù–´\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'price' in df.columns:\n",
    "    print(\"–û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ü–µ–Ω:\")\n",
    "    print(f\"  –ú–∏–Ω–∏–º—É–º:     {df['price'].min():,.0f}‚Ç¨\")\n",
    "    print(f\"  25% (Q1):    {df['price'].quantile(0.25):,.0f}‚Ç¨\")\n",
    "    print(f\"  –ú–µ–¥–∏–∞–Ω–∞:     {df['price'].median():,.0f}‚Ç¨\")\n",
    "    print(f\"  75% (Q3):    {df['price'].quantile(0.75):,.0f}‚Ç¨\")\n",
    "    print(f\"  –ú–∞–∫—Å–∏–º—É–º:    {df['price'].max():,.0f}‚Ç¨\")\n",
    "    print(f\"  –°—Ä–µ–¥–Ω–µ–µ:     {df['price'].mean():,.0f}‚Ç¨\")\n",
    "    print(f\"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ: {df['price'].std():,.0f}‚Ç¨\")\n",
    "    \n",
    "    # –ê–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–æ—Å–æ–≤\n",
    "    Q1 = df['price'].quantile(0.25)\n",
    "    Q3 = df['price'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df['price'] < lower_bound) | (df['price'] > upper_bound)]\n",
    "    print(f\"\\n–ê–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–æ—Å–æ–≤ (–º–µ—Ç–æ–¥ IQR):\")\n",
    "    print(f\"  –ì—Ä–∞–Ω–∏—Ü—ã –≤—ã–±—Ä–æ—Å–æ–≤: [{lower_bound:,.0f}‚Ç¨, {upper_bound:,.0f}‚Ç¨]\")\n",
    "    print(f\"  –í—ã–±—Ä–æ—Å–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {len(outliers):,} ({len(outliers)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# =============================\n",
    "# 6. –ö–û–†–†–ï–õ–Ø–¶–ò–û–ù–ù–´–ô –ê–ù–ê–õ–ò–ó\n",
    "# =============================\n",
    "print(\"\\n6. –ö–û–†–†–ï–õ–Ø–¶–ò–û–ù–ù–´–ô –ê–ù–ê–õ–ò–ó\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# –í—ã–±–∏—Ä–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if len(numeric_cols) > 1:\n",
    "    print(f\"–ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {numeric_cols}\")\n",
    "    \n",
    "    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏\n",
    "    correlation_matrix = df[numeric_cols].corr()\n",
    "    \n",
    "    # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–Ω–æ–π\n",
    "    if 'price' in numeric_cols:\n",
    "        price_corr = correlation_matrix['price'].sort_values(ascending=False)\n",
    "        print(\"\\n–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–Ω–æ–π:\")\n",
    "        for feature, corr_value in price_corr.items():\n",
    "            if feature != 'price':\n",
    "                # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏\n",
    "                if abs(corr_value) > 0.7:\n",
    "                    strength = \"–û–ß–ï–ù–¨ –°–ò–õ–¨–ù–ê–Ø\"\n",
    "                elif abs(corr_value) > 0.5:\n",
    "                    strength = \"–°–ò–õ–¨–ù–ê–Ø\"\n",
    "                elif abs(corr_value) > 0.3:\n",
    "                    strength = \"–£–ú–ï–†–ï–ù–ù–ê–Ø\"\n",
    "                elif abs(corr_value) > 0.1:\n",
    "                    strength = \"–°–õ–ê–ë–ê–Ø\"\n",
    "                else:\n",
    "                    strength = \"–û–ß–ï–ù–¨ –°–õ–ê–ë–ê–Ø\"\n",
    "                \n",
    "                print(f\"  {feature:20} : {corr_value:+.3f} ({strength})\")\n",
    "\n",
    "# =============================\n",
    "# 7. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ö–£–†–°–û–í–û–ô\n",
    "# =============================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ö–£–†–°–û–í–û–ô –†–ê–ë–û–¢–´\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä –û–°–ù–û–í–ù–´–ï –í–´–í–û–î–´ –ò–ó –ü–ï–†–í–ò–ß–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê:\")\n",
    "print(\"1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(f\"   - –û–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö: {df.shape[0]:,} –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π\")\n",
    "print(f\"   - –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {df.shape[1]}\")\n",
    "print(f\"   - –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: —Ü–µ–Ω–∞, –≥–æ–¥ –≤—ã–ø—É—Å–∫–∞, –ø—Ä–æ–±–µ–≥, –º–∞—Ä–∫–∞, —Ç–∏–ø —Ç–æ–ø–ª–∏–≤–∞\")\n",
    "\n",
    "print(\"\\n2. –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(f\"   - –ü—Ä–æ–ø—É—Å–∫–∏: {missing_percent:.1f}% –¥–∞–Ω–Ω—ã—Ö\")\n",
    "print(f\"   - –í—ã–±—Ä–æ—Å—ã –≤ —Ü–µ–Ω–µ: {len(outliers) if 'outliers' in locals() else 'N/A'} –∑–∞–ø–∏—Å–µ–π\")\n",
    "\n",
    "print(\"\\n3. –ó–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏:\")\n",
    "print(\"   - –¶–µ–Ω–∞ —Å–∏–ª—å–Ω–æ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≥–æ–¥–∞ –≤—ã–ø—É—Å–∫–∞\")\n",
    "print(\"   - –ü—Ä–æ–±–µ–≥ –æ–±—Ä–∞—Ç–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å —Ü–µ–Ω–æ–π\")\n",
    "print(\"   - –ü—Ä–µ–º–∏–∞–ª—å–Ω—ã–µ –±—Ä–µ–Ω–¥—ã (BMW, Mercedes) –∏–º–µ—é—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ —Ü–µ–Ω—ã\")\n",
    "\n",
    "print(\"\\nüîß –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:\")\n",
    "print(\"1. –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(\"   - –£–¥–∞–ª–µ–Ω–∏–µ/–∫–æ—Ä—Ä–µ–∫—Ü–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ –≤ —Ü–µ–Ω–µ\")\n",
    "print(\"   - –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö\")\n",
    "print(\"   - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –ª–µ—Ç –≤—ã–ø—É—Å–∫–∞ –∏ –ø—Ä–æ–±–µ–≥–∞\")\n",
    "\n",
    "print(\"\\n2. –£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:\")\n",
    "print(\"   - –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω –ø–æ –º–∞—Ä–∫–∞–º/–º–æ–¥–µ–ª—è–º\")\n",
    "print(\"   - –í–ª–∏—è–Ω–∏–µ —Ç–∏–ø–∞ –∫–æ—Ä–æ–±–∫–∏ –ø–µ—Ä–µ–¥–∞—á –∏ —Ç–æ–ø–ª–∏–≤–∞ –Ω–∞ —Ü–µ–Ω—É\")\n",
    "print(\"   - –ê–Ω–∞–ª–∏–∑ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–æ–¥–∞–∂ (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞—Ç—ã)\")\n",
    "\n",
    "print(\"\\n3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é:\")\n",
    "print(\"   - One-hot encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\")\n",
    "print(\"   - –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\")\n",
    "print(\"   - –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test –≤—ã–±–æ—Ä–∫–∏\")\n",
    "/\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"–ü–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –ì–æ—Ç–æ–≤–æ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –∫—É—Ä—Å–æ–≤—É—é.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf1a22e-ff32-49a1-889d-0b712c4d8e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
